---
title: "Terraform State Management: Collaborating Safely with S3 and DynamoDB"
datePublished: Wed Dec 18 2024 18:26:28 GMT+0000 (Coordinated Universal Time)
cuid: cm4u84uul000609me0t537c5j
slug: terraform-state-management-collaborating-safely-with-s3-and-dynamodb
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1734546237780/eba0e9e6-4f80-4691-a77e-cab84c5409cd.png
tags: aws, dynamodb, terraform, s3, state-management, terraform-state, tfstate, s3-bucket, terraformstatefile, state-locking

---

# Terraform State:

Terraform State allows you to view the current state of any resources you have created on a cloud platform locally.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734452917270/235c0740-a7eb-422c-9b1d-a78469f482f5.png align="center")

When you create an AWS EC2 instance using Terraform, its default state is **"running"**.

When we did terraform apply our AWS Instance knows the instance state is running.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734328569118/887a6a41-1bfd-4315-be52-93d9c95cc34f.png align="center")

Similarly, we can instruct Terraform to display all the states it is managing.

```bash
terraform state list
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734328308152/14bcdd27-1aad-4ed6-a2a9-fd620f6c43eb.png align="center")

Terraform maintains a list of all the resources it has created in the `terraform.tfstate` file. It stores the details that are also available on the AWS console, as shown below:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734452297348/6c7db9cd-3744-48f2-aa78-bb1ec20f11dd.png align="center")

To check the current state of any resource, use the following command:

```bash
terraform state show 'resource_state'
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734452451238/a9a9a640-81a1-4ddb-945e-df9edb53f719.png align="center")

Now we will go to AWS and stop our instance:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734452982754/5beac709-7ead-4829-8f0b-6e06ebd1630f.png align="center")

It will display the status as stopped on the AWS console, so you would expect it to show the same status locally in Terraform. However, if you run `terraform state show aws_instance.my_instance[0]`, you will see it still shows the state as running.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734453118996/74d85e4f-421e-4978-b55b-b9418d547319.png align="left")

This discrepancy occurs because the local Terraform state is not automatically updated with changes made outside of Terraform. To resolve this issue and ensure the local state matches the AWS console, you can use the following command to refresh the state of the resource:

```bash
terraform apply -refresh-only
```

You will see a prompt asking, "Do you want to update the state?" as shown in the image below.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734454026511/36ec76e3-2a3a-4522-9a33-49c6e489ce98.png align="center")

You can see in `terraform.tfstate` that your instance state has been changed to stopped.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734454277697/4e9d04c7-203c-4fe6-a720-82ce884f35f0.png align="center")

This is how you can sync your local setup with AWS or another cloud provider.

---

# State Locking

### Real Scenario:

Our terraform.tfstate have all the information regarding our resource including, AMI ID, Public key, Private Key, etc., We cannot commit it on GitHub because it have all the sensitive information about our infrastructure.

Suppose, **User 1** create a version for state file where he add `instance count = 1` at **10:00 PM**. With this instance count, one instance has been created on AWS and the state file of that instance we did not commit on GitHub because it is sensitive data.

Now, User 2 increase the `instance count = 2` on his system at **10:01 PM** so on AWS two instances has been created.

It is happening because every user `tfstate files` are different.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734501124292/f5f49c72-db8b-4c51-b296-cd2adc885dae.png align="center")

To address this issue, we need a mechanism that locks the state file when it is created, such as at 10:00 PM, ensuring that only a single state file is in use. This should be achieved without relying on GitHub.

### **Problem Statement:**

When multiple users work on Terraform, they each have different state files, leading to disorganization in AWS. To resolve this, we require a single shared state file that doesn't need to be pushed to GitHub.

### **Solution:**

We will store the state file in an **S3 Bucket**, allowing Terraform to read and write the state file from there. However, when using an S3 Bucket, it is necessary to connect it to a database, specifically DynamoDB.

Note: DynamoDB is a key-value pair database that does not use tables and columns.

When we execute `terraform apply`, it will interact with the S3 Bucket. Once accessed, the S3 Bucket will communicate with DynamoDB to track which user is accessing it and what actions they are performing. The user's activity is recorded in DynamoDB, and a LockID is generated. As long as the LockID exists, User 2 must wait until User 1 completes their task and releases the LockID. During this period, no one else can access User 1's S3 resources. This process is known as **<mark>state locking</mark>**.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1734545143274/063a31fc-b4e1-4ac2-8f5f-2a2c3e790fe9.png align="center")

In state locking, we keep a single state file as the source of truth in an S3 bucket. Whenever we apply our Terraform configurations, a LockID is created in a DynamoDB table. As long as the LockID exists, no one else can use the state file. This is how the lock-and-key mechanism works. DynamoDB makes sure there is only one LockID, stopping multiple users from creating one.

Once User 1 finishes their work, the LockID is released, and the state becomes available, allowing another user to access and work with it.

We will see hands-on example in our next blog. Till then stay tuned!

---

## **Happy Learning :)**

**Chetan Mohod âœ¨**

For more DevOps updates, you can follow me on [**LinkedIn**](https://www.linkedin.com/in/chetanmohod/).